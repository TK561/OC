"""
å±•ç¤ºç”¨è»½é‡ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ - MiDaS v3.1ç‰ˆ
å®Œå…¨ç„¡æ–™ãƒ»ãƒ­ãƒ¼ã‚«ãƒ«ãƒ»é«˜ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ»CPUæœ€é©åŒ–
"""

from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import torch
import torchvision.transforms as transforms
from PIL import Image
import numpy as np
import cv2
import io
import base64
import gc
import logging
import urllib.request
import os
from datetime import datetime
from pathlib import Path

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('exhibition_lightweight.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

app = FastAPI(
    title="å±•ç¤ºç”¨è»½é‡æ·±åº¦æ¨å®šAPI",
    description="MiDaS v3.1 - å®Œå…¨ç„¡æ–™ãƒ»ãƒ­ãƒ¼ã‚«ãƒ«ãƒ»CPUæœ€é©åŒ–ç‰ˆ",
    version="1.0.0"
)

# CORSè¨­å®š (ãƒ­ãƒ¼ã‚«ãƒ«å°‚ç”¨)
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000",
        "http://127.0.0.1:3000",
        "http://localhost:3001"
    ],
    allow_credentials=True,
    allow_methods=["GET", "POST"],
    allow_headers=["*"],
)

class LightweightDepthEstimator:
    def __init__(self, force_cpu=False):
        self.device = "cpu" if force_cpu or not torch.cuda.is_available() else "cuda"
        self.model_path = Path("models")
        self.model_path.mkdir(exist_ok=True)
        
        logger.info(f"ğŸ›ï¸ è»½é‡å±•ç¤ºã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–é–‹å§‹")
        logger.info(f"ğŸ”§ ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {self.device}")
        
        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®š
        self.max_image_size = 1024  # è»½é‡åŒ–ã®ãŸã‚å°ã•ã
        self.allowed_formats = ["image/jpeg", "image/png", "image/webp"]
        self.processing_count = 0
        
        # MiDaS v3.1 åˆæœŸåŒ–
        self.setup_midas()
        
        logger.info(f"âœ… è»½é‡ã‚·ã‚¹ãƒ†ãƒ æº–å‚™å®Œäº†")
        logger.info(f"ğŸ”’ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®šå®Œäº†")
    
    def download_midas_model(self):
        """MiDaS v3.1 ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
        model_file = self.model_path / "midas_v31_small.pt"
        
        if model_file.exists():
            logger.info("ğŸ“¦ MiDaS ãƒ¢ãƒ‡ãƒ«: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰èª­ã¿è¾¼ã¿")
            return str(model_file)
        
        logger.info("ğŸ“¥ MiDaS v3.1 Small ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
        
        # MiDaS v3.1 Small (è»½é‡ç‰ˆ)
        model_url = "https://github.com/isl-org/MiDaS/releases/download/v3_1/midas_v31_small.pt"
        
        try:
            urllib.request.urlretrieve(model_url, model_file)
            logger.info(f"âœ… ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†: {model_file}")
            return str(model_file)
        except Exception as e:
            logger.error(f"âŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
            raise e
    
    def setup_midas(self):
        """MiDaS v3.1 ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        try:
            # PyTorch HubçµŒç”±ã§MiDaSèª­ã¿è¾¼ã¿ï¼ˆè»½é‡ç‰ˆï¼‰
            logger.info("ğŸ”„ MiDaS v3.1 Small ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­...")
            
            # è»½é‡ç‰ˆMiDaSã‚’ä½¿ç”¨
            self.model = torch.hub.load('intel-isl/MiDaS', 'MiDaS_small')
            self.model.to(self.device)
            self.model.eval()
            
            # å‰å‡¦ç†è¨­å®š
            self.midas_transforms = torch.hub.load('intel-isl/MiDaS', 'transforms')
            if self.device == "cpu":
                # CPUæœ€é©åŒ–å¤‰æ›
                self.transform = self.midas_transforms.small_transform
            else:
                self.transform = self.midas_transforms.small_transform
            
            logger.info(f"âœ… MiDaS v3.1 Small èª­ã¿è¾¼ã¿å®Œäº†")
            logger.info(f"ğŸ’¾ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: è»½é‡æœ€é©åŒ–")
            
        except Exception as e:
            logger.error(f"âŒ MiDaSåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            raise e
    
    def validate_image(self, file: UploadFile):
        """ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®å®‰å…¨æ€§æ¤œè¨¼"""
        if file.content_type not in self.allowed_formats:
            raise HTTPException(
                status_code=400,
                detail=f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„å½¢å¼: {file.content_type}"
            )
        
        if hasattr(file, 'size') and file.size > 5 * 1024 * 1024:  # 5MBåˆ¶é™
            raise HTTPException(
                status_code=400,
                detail="ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã™ãã¾ã™ (æœ€å¤§5MB)"
            )
        
        return True
    
    def process_image(self, image_data: bytes):
        """ã‚»ã‚­ãƒ¥ã‚¢ãªç”»åƒå‡¦ç†"""
        try:
            image = Image.open(io.BytesIO(image_data)).convert('RGB')
            original_size = image.size
            
            # ã‚µã‚¤ã‚ºåˆ¶é™ï¼ˆè»½é‡åŒ–ï¼‰
            if max(image.size) > self.max_image_size:
                image.thumbnail((self.max_image_size, self.max_image_size), Image.Resampling.LANCZOS)
                logger.info(f"ğŸ“ ç”»åƒãƒªã‚µã‚¤ã‚º: {original_size} â†’ {image.size}")
            
            return image, original_size
            
        except Exception as e:
            logger.error(f"âŒ ç”»åƒå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            raise HTTPException(status_code=400, detail="ç”»åƒã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
    
    def estimate_depth_midas(self, image: Image.Image):
        """MiDaS v3.1 æ·±åº¦æ¨å®š"""
        try:
            # NumPyé…åˆ—ã«å¤‰æ›
            img_array = np.array(image)
            
            # MiDaSå‰å‡¦ç†
            input_tensor = self.transform(img_array).to(self.device)
            
            # æ¨è«–å®Ÿè¡Œ
            with torch.no_grad():
                prediction = self.model(input_tensor)
                prediction = torch.nn.functional.interpolate(
                    prediction.unsqueeze(1),
                    size=img_array.shape[:2],
                    mode="bicubic",
                    align_corners=False,
                ).squeeze()
            
            # æ·±åº¦ãƒãƒƒãƒ—ç”Ÿæˆ
            depth = prediction.cpu().numpy()
            
            # æ­£è¦åŒ–
            depth_min = depth.min()
            depth_max = depth.max()
            depth_normalized = ((depth - depth_min) / (depth_max - depth_min) * 255).astype(np.uint8)
            
            # ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—é©ç”¨
            depth_colored = cv2.applyColorMap(depth_normalized, cv2.COLORMAP_VIRIDIS)
            depth_colored = cv2.cvtColor(depth_colored, cv2.COLOR_BGR2RGB)
            
            # PILã‚¤ãƒ¡ãƒ¼ã‚¸ã«å¤‰æ›
            depth_image = Image.fromarray(depth_colored)
            
            # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            del input_tensor, prediction, depth, depth_normalized, depth_colored
            
            return depth_image
            
        except Exception as e:
            logger.error(f"âŒ MiDaSæ·±åº¦æ¨å®šã‚¨ãƒ©ãƒ¼: {e}")
            raise HTTPException(status_code=500, detail="æ·±åº¦æ¨å®šå‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ")
        
        finally:
            # CPU/GPU ãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            gc.collect()
    
    def encode_image_to_base64(self, image: Image.Image, format='PNG'):
        """ç”»åƒã‚’Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰"""
        buffer = io.BytesIO()
        image.save(buffer, format=format)
        encoded = base64.b64encode(buffer.getvalue()).decode()
        return f"data:image/{format.lower()};base64,{encoded}"

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ï¼ˆCPUæœ€é©åŒ–ï¼‰
estimator = LightweightDepthEstimator(force_cpu=True)  # å±•ç¤ºç”¨ã¯CPUæ¨å¥¨

@app.get("/")
async def root():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    return {
        "status": "ğŸ›ï¸ è»½é‡å±•ç¤ºç”¨æ·±åº¦æ¨å®šAPIç¨¼åƒä¸­",
        "model": "MiDaS v3.1 Small",
        "device": estimator.device,
        "processed_count": estimator.processing_count,
        "license": "MIT (å®Œå…¨ç„¡æ–™)",
        "timestamp": datetime.now().isoformat()
    }

@app.get("/health")
async def health_check():
    """è©³ç´°ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    cpu_memory = None
    try:
        import psutil
        cpu_memory = f"{psutil.virtual_memory().percent}%"
    except ImportError:
        cpu_memory = "N/A"
    
    gpu_memory = None
    if torch.cuda.is_available() and estimator.device == "cuda":
        gpu_memory = {
            "allocated": f"{torch.cuda.memory_allocated() / 1024**3:.2f}GB",
            "reserved": f"{torch.cuda.memory_reserved() / 1024**3:.2f}GB"
        }
    
    return {
        "status": "healthy",
        "model": "MiDaS v3.1 Small",
        "device": estimator.device,
        "cpu_memory": cpu_memory,
        "gpu_memory": gpu_memory,
        "processed_count": estimator.processing_count,
        "license": "MIT License",
        "cost": "å®Œå…¨ç„¡æ–™"
    }

@app.post("/api/depth-estimation")
async def estimate_depth_api(file: UploadFile = File(...)):
    """è»½é‡æ·±åº¦æ¨å®šAPI"""
    request_id = f"req_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{estimator.processing_count}"
    
    try:
        logger.info(f"ğŸ“¥ æ–°ã—ã„ãƒªã‚¯ã‚¨ã‚¹ãƒˆ: {request_id}")
        estimator.processing_count += 1
        
        # å…¥åŠ›æ¤œè¨¼
        estimator.validate_image(file)
        
        # ç”»åƒãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        image_data = await file.read()
        logger.info(f"ğŸ“Š ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {len(image_data)} bytes")
        
        # ç”»åƒå‡¦ç†
        image, original_size = estimator.process_image(image_data)
        
        # MiDaSæ·±åº¦æ¨å®šå®Ÿè¡Œ
        start_time = datetime.now()
        depth_image = estimator.estimate_depth_midas(image)
        process_time = (datetime.now() - start_time).total_seconds()
        
        # Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        original_base64 = estimator.encode_image_to_base64(image)
        depth_base64 = estimator.encode_image_to_base64(depth_image)
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ä½œæˆ
        response = {
            "success": True,
            "data": [original_base64, depth_base64],  # Gradioäº’æ›å½¢å¼
            "metadata": {
                "request_id": request_id,
                "model": "MiDaS-v3.1-Small",
                "license": "MIT (å®Œå…¨ç„¡æ–™)",
                "original_size": original_size,
                "processed_size": image.size,
                "device": estimator.device,
                "process_time": f"{process_time:.2f}ç§’",
                "security": "å®Œå…¨ãƒ­ãƒ¼ã‚«ãƒ«å‡¦ç†",
                "cost": "ç„¡æ–™",
                "timestamp": datetime.now().isoformat()
            }
        }
        
        logger.info(f"âœ… å‡¦ç†å®Œäº†: {request_id} ({process_time:.2f}ç§’)")
        
        # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        del image_data, image, depth_image
        gc.collect()
        
        return JSONResponse(content=response)
        
    except HTTPException as he:
        logger.warning(f"âš ï¸ ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼ {request_id}: {he.detail}")
        raise he
        
    except Exception as e:
        logger.error(f"âŒ å‡¦ç†ã‚¨ãƒ©ãƒ¼ {request_id}: {e}")
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "error": "ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ",
                "request_id": request_id
            }
        )
    
    finally:
        # æœ€çµ‚ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        gc.collect()

@app.get("/api/cost-info")
async def cost_info():
    """ã‚³ã‚¹ãƒˆæƒ…å ±"""
    return {
        "model": "MiDaS v3.1 Small",
        "license": "MIT License",
        "cost_breakdown": {
            "software": "å®Œå…¨ç„¡æ–™",
            "model": "å®Œå…¨ç„¡æ–™",
            "api_calls": "ç„¡åˆ¶é™",
            "commercial_use": "å¯èƒ½",
            "modification": "å¯èƒ½",
            "distribution": "å¯èƒ½"
        },
        "hardware_requirements": {
            "minimum": "CPU: Intel i5, RAM: 8GB",
            "recommended": "CPU: Intel i7, RAM: 16GB",
            "gpu_required": False
        },
        "estimated_costs": {
            "initial_setup": "PCä»£ã®ã¿ (15-30ä¸‡å††)",
            "running_cost": "é›»æ°—ä»£ã®ã¿ (æœˆæ•°åƒå††)",
            "maintenance": "ç„¡æ–™",
            "updates": "ç„¡æ–™"
        }
    }

if __name__ == "__main__":
    import uvicorn
    
    logger.info("ğŸ›ï¸ è»½é‡å±•ç¤ºç”¨æ·±åº¦æ¨å®šã‚·ã‚¹ãƒ†ãƒ èµ·å‹•")
    logger.info("ğŸ’° å®Œå…¨ç„¡æ–™ãƒ»MITãƒ©ã‚¤ã‚»ãƒ³ã‚¹")
    logger.info("ğŸ”’ å®Œå…¨ãƒ­ãƒ¼ã‚«ãƒ«ãƒ»é«˜ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£")
    logger.info("âš¡ CPUæœ€é©åŒ–ãƒ»è»½é‡è¨­è¨ˆ")
    
    uvicorn.run(
        app, 
        host="0.0.0.0", 
        port=8000,
        log_level="info",
        access_log=True
    )