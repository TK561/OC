#!/usr/bin/env python3
"""
å±•ç¤ºç”¨ãƒ­ãƒ¼ã‚«ãƒ«æ·±åº¦æ¨å®šã‚·ã‚¹ãƒ†ãƒ  - ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import subprocess
import sys
import torch
import os
from pathlib import Path

def check_gpu():
    """GPUä½¿ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯"""
    print("ğŸ” GPUç’°å¢ƒãƒã‚§ãƒƒã‚¯ä¸­...")
    
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        print(f"âœ… GPUæ¤œå‡º: {gpu_name}")
        print(f"âœ… GPU ãƒ¡ãƒ¢ãƒª: {gpu_memory:.1f}GB")
        return True
    else:
        print("âš ï¸ GPUæœªæ¤œå‡º - CPUå®Ÿè¡Œã«ãªã‚Šã¾ã™")
        print("   å±•ç¤ºç”¨ã«ã¯GPUæ¨å¥¨ã§ã™")
        return False

def download_model():
    """ãƒ¢ãƒ‡ãƒ«äº‹å‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    print("ğŸ“¥ DepthAnything V2 ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
    
    try:
        from transformers import AutoImageProcessor, AutoModelForDepthEstimation
        
        model_name = "depth-anything/Depth-Anything-V2-Small-hf"
        
        print("   ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰...")
        processor = AutoImageProcessor.from_pretrained(model_name)
        
        print("   ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰...")
        model = AutoModelForDepthEstimation.from_pretrained(model_name)
        
        print("âœ… ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†")
        print(f"   ä¿å­˜å ´æ‰€: ~/.cache/huggingface/")
        
        return True
        
    except Exception as e:
        print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def create_startup_script():
    """èµ·å‹•ã‚¹ã‚¯ãƒªãƒ—ãƒˆä½œæˆ"""
    print("ğŸ“ èµ·å‹•ã‚¹ã‚¯ãƒªãƒ—ãƒˆä½œæˆä¸­...")
    
    # Windows ãƒãƒƒãƒãƒ•ã‚¡ã‚¤ãƒ«
    batch_content = """@echo off
echo ğŸ›ï¸ å±•ç¤ºç”¨æ·±åº¦æ¨å®šã‚·ã‚¹ãƒ†ãƒ èµ·å‹•ä¸­...
echo.

REM ä»®æƒ³ç’°å¢ƒã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ãƒˆï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
REM call conda activate depth_estimation

REM API ã‚µãƒ¼ãƒãƒ¼èµ·å‹•
python main.py

pause
"""
    
    with open("start_exhibition.bat", "w", encoding="utf-8") as f:
        f.write(batch_content)
    
    # Linux/Mac ã‚·ã‚§ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
    shell_content = """#!/bin/bash
echo "ğŸ›ï¸ å±•ç¤ºç”¨æ·±åº¦æ¨å®šã‚·ã‚¹ãƒ†ãƒ èµ·å‹•ä¸­..."
echo

# ä»®æƒ³ç’°å¢ƒã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ãƒˆï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
# source activate depth_estimation

# API ã‚µãƒ¼ãƒãƒ¼èµ·å‹•
python main.py
"""
    
    with open("start_exhibition.sh", "w") as f:
        f.write(shell_content)
    
    # å®Ÿè¡Œæ¨©é™ä»˜ä¸
    if os.name != 'nt':
        os.chmod("start_exhibition.sh", 0o755)
    
    print("âœ… èµ·å‹•ã‚¹ã‚¯ãƒªãƒ—ãƒˆä½œæˆå®Œäº†")
    print("   Windows: start_exhibition.bat")
    print("   Linux/Mac: start_exhibition.sh")

def create_config():
    """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ"""
    print("âš™ï¸ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆä¸­...")
    
    config_content = """# å±•ç¤ºç”¨è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
{
    "system": {
        "name": "å±•ç¤ºç”¨æ·±åº¦æ¨å®šã‚·ã‚¹ãƒ†ãƒ ",
        "version": "1.0.0",
        "mode": "exhibition"
    },
    "security": {
        "local_only": true,
        "max_image_size": 2048,
        "allowed_formats": ["image/jpeg", "image/png", "image/webp"],
        "auto_cleanup": true
    },
    "performance": {
        "gpu_memory_fraction": 0.8,
        "batch_size": 1,
        "precision": "fp16"
    },
    "exhibition": {
        "touch_interface": true,
        "auto_demo": false,
        "display_processing_time": true,
        "log_visitor_count": true
    }
}
"""
    
    with open("config.json", "w", encoding="utf-8") as f:
        f.write(config_content)
    
    print("âœ… è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆå®Œäº†: config.json")

def setup_logging():
    """ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ"""
    print("ğŸ“ ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆä¸­...")
    
    log_dir = Path("logs")
    log_dir.mkdir(exist_ok=True)
    
    print("âœ… ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆå®Œäº†: logs/")

def main():
    """ãƒ¡ã‚¤ãƒ³ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å‡¦ç†"""
    print("ğŸ›ï¸" + "="*50)
    print("   å±•ç¤ºç”¨æ·±åº¦æ¨å®šã‚·ã‚¹ãƒ†ãƒ  - ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—")
    print("="*53)
    print()
    
    # 1. GPU ãƒã‚§ãƒƒã‚¯
    gpu_available = check_gpu()
    print()
    
    # 2. ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    if not download_model():
        print("âŒ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å¤±æ•—: ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return False
    print()
    
    # 3. èµ·å‹•ã‚¹ã‚¯ãƒªãƒ—ãƒˆä½œæˆ
    create_startup_script()
    print()
    
    # 4. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
    create_config()
    print()
    
    # 5. ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    setup_logging()
    print()
    
    # ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†
    print("ğŸ‰ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†!")
    print()
    print("ğŸ“‹ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("   1. ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã®ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰URLã‚’å¤‰æ›´:")
    print("      NEXT_PUBLIC_BACKEND_URL=http://localhost:8000")
    print()
    print("   2. ã‚·ã‚¹ãƒ†ãƒ èµ·å‹•:")
    if os.name == 'nt':
        print("      start_exhibition.bat ã‚’ãƒ€ãƒ–ãƒ«ã‚¯ãƒªãƒƒã‚¯")
    else:
        print("      ./start_exhibition.sh")
    print()
    print("   3. ãƒ–ãƒ©ã‚¦ã‚¶ã§ç¢ºèª:")
    print("      http://localhost:8000/ (API)")
    print("      http://localhost:3000/ (ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰)")
    print()
    
    if not gpu_available:
        print("âš ï¸ æ³¨æ„: GPUæœªæ¤œå‡º")
        print("   å±•ç¤ºç”¨é€”ã§ã¯å‡¦ç†æ™‚é–“ãŒé•·ããªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
        print("   GPUãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã¨CUDAã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚’æ¨å¥¨ã—ã¾ã™")
    
    print("ğŸ”’ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£: å®Œå…¨ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œã§æœ€é«˜ãƒ¬ãƒ™ãƒ«ã®å®‰å…¨æ€§")
    
    return True

if __name__ == "__main__":
    try:
        success = main()
        if not success:
            sys.exit(1)
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)