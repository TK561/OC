"""
Google Colabç”¨æ·±åº¦æ¨å®šAPI - ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼é‡è¦–ç‰ˆ
DepthAnything V2ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ãŸæœ¬æ ¼çš„ãªæ·±åº¦æ¨å®šã‚µãƒ¼ãƒ“ã‚¹

ğŸ”’ ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒ»ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ©Ÿèƒ½:
- ç”»åƒã®ä¸€æ™‚çš„å‡¦ç†ã®ã¿ï¼ˆä¿å­˜ãªã—ï¼‰
- ãƒ¡ãƒ¢ãƒªå†…å‡¦ç†å¾Œå³åº§ã«å‰Šé™¤
- ãƒ­ã‚°ã«ç”»åƒãƒ‡ãƒ¼ã‚¿å‡ºåŠ›ãªã—
- ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†æ™‚ã®è‡ªå‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—

ä½¿ç”¨æ–¹æ³•:
1. Google Colabã§ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å®Ÿè¡Œ
2. ngrokãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¨­å®š
3. ç”Ÿæˆã•ã‚ŒãŸURLã‚’ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã®NEXT_PUBLIC_BACKEND_URLã«è¨­å®š
"""

import os
import io
import base64
import numpy as np
from PIL import Image
import torch
import gradio as gr
from transformers import pipeline, AutoImageProcessor, AutoModelForDepthEstimation
import cv2
import gc
import tempfile
import time
import logging

# ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼é‡è¦–ã®ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ã‚°ã«å‡ºåŠ›ã—ãªã„ã‚ˆã†ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
class PrivacyLogFilter(logging.Filter):
    def filter(self, record):
        # Base64ã‚„ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚‰ã—ãé•·ã„æ–‡å­—åˆ—ã‚’ãƒ­ã‚°ã‹ã‚‰é™¤å¤–
        if hasattr(record, 'msg') and isinstance(record.msg, str):
            if 'data:image' in record.msg or len(record.msg) > 1000:
                return False
        return True

logger.addFilter(PrivacyLogFilter())

class DepthEstimationAPI:
    def __init__(self):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        logger.info(f"ğŸš€ Initializing secure depth estimation API on {self.device}")
        
        # DepthAnything V2ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
        self.model_name = "depth-anything/Depth-Anything-V2-Small-hf"
        self.processor = AutoImageProcessor.from_pretrained(self.model_name)
        self.model = AutoModelForDepthEstimation.from_pretrained(self.model_name)
        self.model.to(self.device)
        
        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®š
        self.max_image_size = 2048  # æœ€å¤§ç”»åƒã‚µã‚¤ã‚ºåˆ¶é™
        self.session_timeout = 3600  # 1æ™‚é–“ã§ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
        self.processing_sessions = {}  # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†
        
        logger.info(f"âœ… Model loaded: {self.model_name}")
        logger.info(f"ğŸ”’ Security features enabled: max_size={self.max_image_size}px")
    
    def cleanup_session(self, session_id):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        if session_id in self.processing_sessions:
            del self.processing_sessions[session_id]
        gc.collect()  # ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
        if torch.cuda.is_available():
            torch.cuda.empty_cache()  # GPU ãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢
    
    def validate_image(self, image):
        """ç”»åƒã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ¤œè¨¼"""
        # ã‚µã‚¤ã‚ºåˆ¶é™
        if max(image.size) > self.max_image_size:
            raise ValueError(f"ç”»åƒã‚µã‚¤ã‚ºãŒå¤§ãã™ãã¾ã™ã€‚æœ€å¤§{self.max_image_size}pxä»¥ä¸‹ã«ã—ã¦ãã ã•ã„ã€‚")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ãƒã‚§ãƒƒã‚¯
        if image.format not in ['JPEG', 'PNG', 'WEBP']:
            logger.warning(f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ç”»åƒå½¢å¼: {image.format}")
        
        return True
    
    def preprocess_image(self, image_input, session_id=None):
        """ã‚»ã‚­ãƒ¥ã‚¢ãªç”»åƒå‰å‡¦ç†"""
        try:
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³è¨˜éŒ²
            if session_id:
                self.processing_sessions[session_id] = {
                    'start_time': time.time(),
                    'status': 'preprocessing'
                }
            
            if isinstance(image_input, str):
                # Base64 ãƒ‡ãƒ¼ã‚¿URLã®å ´åˆ
                if image_input.startswith('data:'):
                    header, data = image_input.split(',', 1)
                    image_data = base64.b64decode(data)
                    image = Image.open(io.BytesIO(image_data))
                else:
                    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®å ´åˆï¼ˆã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä¸Šæ¨å¥¨ã—ãªã„ï¼‰
                    logger.warning("ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹çµŒç”±ã®ç”»åƒèª­ã¿è¾¼ã¿ã¯æ¨å¥¨ã•ã‚Œã¾ã›ã‚“")
                    image = Image.open(image_input)
            else:
                # PIL Imageã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å ´åˆ
                image = image_input
            
            # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ¤œè¨¼
            self.validate_image(image)
            
            # RGBã«å¤‰æ›
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            logger.info(f"ğŸ–¼ï¸ Image processed: {image.size[0]}x{image.size[1]}px")
            return image
            
        except Exception as e:
            logger.error(f"âŒ Image preprocessing failed: {str(e)}")
            if session_id:
                self.cleanup_session(session_id)
            raise e
    
    def estimate_depth(self, image_input):
        """ã‚»ã‚­ãƒ¥ã‚¢ãªæ·±åº¦æ¨å®šå‡¦ç†"""
        session_id = str(time.time())  # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªã‚»ãƒƒã‚·ãƒ§ãƒ³ID
        
        try:
            # ç”»åƒã®å‰å‡¦ç†ï¼ˆã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯å«ã‚€ï¼‰
            image = self.preprocess_image(image_input, session_id)
            original_size = image.size
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³æ›´æ–°
            if session_id in self.processing_sessions:
                self.processing_sessions[session_id]['status'] = 'inference'
            
            logger.info(f"ğŸ”„ Starting depth estimation for session {session_id}")
            
            # ãƒ¢ãƒ‡ãƒ«æ¨è«–
            inputs = self.processor(images=image, return_tensors="pt")
            inputs = {k: v.to(self.device) for k, v in inputs.items()}
            
            with torch.no_grad():
                outputs = self.model(**inputs)
                predicted_depth = outputs.predicted_depth
            
            # æ·±åº¦ãƒãƒƒãƒ—ã®å¾Œå‡¦ç†
            depth = predicted_depth.squeeze().cpu().numpy()
            
            # æ­£è¦åŒ– (0-255)
            depth_min = depth.min()
            depth_max = depth.max()
            depth_normalized = ((depth - depth_min) / (depth_max - depth_min) * 255).astype(np.uint8)
            
            # å…ƒã®ã‚µã‚¤ã‚ºã«ãƒªã‚µã‚¤ã‚º
            depth_resized = cv2.resize(depth_normalized, original_size, interpolation=cv2.INTER_LINEAR)
            
            # ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—ã‚’é©ç”¨ (viridis)
            depth_colored = cv2.applyColorMap(depth_resized, cv2.COLORMAP_VIRIDIS)
            depth_colored = cv2.cvtColor(depth_colored, cv2.COLOR_BGR2RGB)
            
            # PILã‚¤ãƒ¡ãƒ¼ã‚¸ã«å¤‰æ›
            depth_image = Image.fromarray(depth_colored)
            
            logger.info(f"âœ… Depth estimation completed for session {session_id}")
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            self.cleanup_session(session_id)
            
            # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚’æ˜ç¤ºçš„ã«å‰Šé™¤ï¼ˆãƒ¡ãƒ¢ãƒªä¿è­·ï¼‰
            del inputs, outputs, predicted_depth, depth, depth_normalized, depth_resized, depth_colored
            
            return image, depth_image
            
        except Exception as e:
            logger.error(f"âŒ Depth estimation failed for session {session_id}: {str(e)}")
            self.cleanup_session(session_id)
            return None, None
    
    def process_api_request(self, image_input):
        """ã‚»ã‚­ãƒ¥ã‚¢ãªGradio APIå‡¦ç†é–¢æ•°"""
        request_id = str(time.time())
        
        try:
            logger.info(f"ğŸ“¥ New API request: {request_id}")
            
            if image_input is None:
                logger.warning("âŒ No image provided in request")
                return None, None
            
            # æ·±åº¦æ¨å®šå®Ÿè¡Œ
            original, depth = self.estimate_depth(image_input)
            
            if original is None or depth is None:
                logger.error(f"âŒ Processing failed for request {request_id}")
                return None, None
            
            logger.info(f"âœ… Request completed successfully: {request_id}")
            return original, depth
            
        except Exception as e:
            logger.error(f"âŒ API request failed {request_id}: {str(e)}")
            return None, None
        finally:
            # ãƒªã‚¯ã‚¨ã‚¹ãƒˆå®Œäº†å¾Œã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

# ã‚°ãƒ­ãƒ¼ãƒãƒ«API ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
api = DepthEstimationAPI()

def gradio_interface():
    """ã‚»ã‚­ãƒ¥ã‚¢ãªGradio ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®è¨­å®š"""
    
    # ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼é‡è¦–ã®èª¬æ˜æ–‡
    privacy_notice = """
    ğŸ”’ **ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¿è­·å‹æ·±åº¦æ¨å®šAPI**
    
    - âœ… ç”»åƒã¯ä¸€æ™‚çš„å‡¦ç†ã®ã¿ï¼ˆä¿å­˜ã•ã‚Œã¾ã›ã‚“ï¼‰
    - âœ… å‡¦ç†å®Œäº†å¾Œã€ãƒ¡ãƒ¢ãƒªã‹ã‚‰å³åº§ã«å‰Šé™¤
    - âœ… ãƒ­ã‚°ã«ç”»åƒãƒ‡ãƒ¼ã‚¿ã¯è¨˜éŒ²ã•ã‚Œã¾ã›ã‚“
    - âœ… ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†æ™‚ã«è‡ªå‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    
    æœ€å¤§ç”»åƒã‚µã‚¤ã‚º: 2048px | å¯¾å¿œå½¢å¼: JPEG, PNG, WebP
    """
    
    interface = gr.Interface(
        fn=api.process_api_request,
        inputs=gr.Image(
            type="pil", 
            label="ğŸ“· æ·±åº¦æ¨å®šã™ã‚‹ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
            sources=["upload", "webcam"]  # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¨Webã‚«ãƒ¡ãƒ©
        ),
        outputs=[
            gr.Image(type="pil", label="ğŸ“¸ å…ƒç”»åƒ"),
            gr.Image(type="pil", label="ğŸ¨ æ·±åº¦ãƒãƒƒãƒ—")
        ],
        title="ğŸ”’ DepthAnything V2 - ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¿è­·å‹æ·±åº¦æ¨å®šAPI",
        description=privacy_notice,
        examples=[],
        allow_flagging="never",  # ãƒ•ãƒ©ã‚°æ©Ÿèƒ½ç„¡åŠ¹ï¼ˆãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¿è­·ï¼‰
        analytics_enabled=False,  # ã‚¢ãƒŠãƒªãƒ†ã‚£ã‚¯ã‚¹ç„¡åŠ¹
        show_error=True,  # ã‚¨ãƒ©ãƒ¼è¡¨ç¤ºã¯æœ‰åŠ¹
        cache_examples=False  # ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã‚­ãƒ£ãƒƒã‚·ãƒ¥ç„¡åŠ¹
    )
    
    return interface

# ngrokè¨­å®šã¨ã‚µãƒ¼ãƒãƒ¼èµ·å‹•
def setup_ngrok():
    """ngrokã®è¨­å®šã¨ãƒˆãƒ³ãƒãƒ«ä½œæˆ"""
    try:
        import pyngrok
        from pyngrok import ngrok
        
        # ngrokãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¨­å®š (Colabã®å ´åˆã¯æœ€åˆã«è¨­å®šãŒå¿…è¦)
        # ngrok.set_auth_token("YOUR_NGROK_TOKEN")  # å®Ÿéš›ã®ãƒˆãƒ¼ã‚¯ãƒ³ã«ç½®ãæ›ãˆ
        
        # ãƒˆãƒ³ãƒãƒ«ã‚’ä½œæˆ
        public_url = ngrok.connect(7860)
        print(f"Public URL: {public_url}")
        print(f"Frontendç’°å¢ƒå¤‰æ•°ã«è¨­å®šã—ã¦ãã ã•ã„:")
        print(f"NEXT_PUBLIC_BACKEND_URL={public_url}")
        
        return public_url
        
    except ImportError:
        print("pyngrokãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        print("!pip install pyngrok ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        return None
    except Exception as e:
        print(f"ngrokè¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
        return None

if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ”’ DepthAnything V2 ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¿è­·å‹æ·±åº¦æ¨å®šAPI")
    print("=" * 60)
    
    logger.info("ğŸš€ Starting secure depth estimation server...")
    
    # Gradio ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’ä½œæˆ
    demo = gradio_interface()
    
    # ngrokã§ãƒ‘ãƒ–ãƒªãƒƒã‚¯URLã‚’å–å¾—
    logger.info("ğŸŒ Setting up ngrok tunnel...")
    public_url = setup_ngrok()
    
    # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æƒ…å ±è¡¨ç¤º
    print("\n" + "=" * 60)
    print("ğŸ”’ SECURITY FEATURES ENABLED:")
    print("  âœ… No image storage - temporary processing only")
    print("  âœ… Automatic memory cleanup after processing")
    print("  âœ… No image data in logs")
    print("  âœ… Session timeout protection")
    print("  âœ… Image size validation")
    print("  âœ… Gradio analytics disabled")
    print("=" * 60)
    
    # ã‚µãƒ¼ãƒãƒ¼èµ·å‹•
    logger.info("ğŸš€ Launching secure server...")
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,  # ngrokã‚’ä½¿ç”¨ã™ã‚‹ã®ã§False
        debug=False,  # ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¿è­·ã®ãŸã‚debugãƒ¢ãƒ¼ãƒ‰ç„¡åŠ¹
        show_api=False,  # APIä»•æ§˜è¡¨ç¤ºç„¡åŠ¹
        quiet=True  # èµ·å‹•ãƒ­ã‚°æœ€å°åŒ–
    )