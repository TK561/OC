{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DepthAnything V2 深度推定API - Google Colab設定\n",
        "\n",
        "このノートブックを使って、Google Colab上で深度推定APIサーバーを起動します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 必要なライブラリのインストール"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GPU使用可能か確認\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 必要なライブラリをインストール\n",
        "!pip install torch torchvision transformers\n",
        "!pip install gradio\n",
        "!pip install pyngrok\n",
        "!pip install opencv-python-headless\n",
        "!pip install Pillow numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. ngrokトークンの設定\n",
        "\n",
        "1. [ngrok.com](https://ngrok.com)でアカウント作成\n",
        "2. Dashboard > Your Authtoken からトークンをコピー\n",
        "3. 下のセルでトークンを設定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ngrokトークンを設定\n",
        "import pyngrok\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# ここにngrokトークンを入力\n",
        "NGROK_TOKEN = \"YOUR_NGROK_TOKEN_HERE\"  # 実際のトークンに置き換え\n",
        "\n",
        "ngrok.set_auth_token(NGROK_TOKEN)\n",
        "print(\"ngrok認証完了\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 深度推定APIコードの準備"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# APIコードを作成\n",
        "api_code = '''\n",
        "import os\n",
        "import io\n",
        "import base64\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import gradio as gr\n",
        "from transformers import pipeline, AutoImageProcessor, AutoModelForDepthEstimation\n",
        "import cv2\n",
        "from pyngrok import ngrok\n",
        "\n",
        "class DepthEstimationAPI:\n",
        "    def __init__(self):\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        print(f\"Using device: {self.device}\")\n",
        "        \n",
        "        # DepthAnything V2モデルの初期化\n",
        "        self.model_name = \"depth-anything/Depth-Anything-V2-Small-hf\"\n",
        "        print(f\"Loading model: {self.model_name}\")\n",
        "        self.processor = AutoImageProcessor.from_pretrained(self.model_name)\n",
        "        self.model = AutoModelForDepthEstimation.from_pretrained(self.model_name)\n",
        "        self.model.to(self.device)\n",
        "        \n",
        "        print(f\"Model loaded successfully on {self.device}\")\n",
        "    \n",
        "    def estimate_depth(self, image):\n",
        "        \"\"\"深度推定のメイン処理\"\"\"\n",
        "        try:\n",
        "            if image is None:\n",
        "                return None, None\n",
        "            \n",
        "            # RGBに変換\n",
        "            if image.mode != \\'RGB\\':\n",
        "                image = image.convert(\\'RGB\\')\n",
        "            \n",
        "            original_size = image.size\n",
        "            \n",
        "            # モデル推論\n",
        "            inputs = self.processor(images=image, return_tensors=\"pt\")\n",
        "            inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(**inputs)\n",
        "                predicted_depth = outputs.predicted_depth\n",
        "            \n",
        "            # 深度マップの後処理\n",
        "            depth = predicted_depth.squeeze().cpu().numpy()\n",
        "            \n",
        "            # 正規化 (0-255)\n",
        "            depth_min = depth.min()\n",
        "            depth_max = depth.max()\n",
        "            depth_normalized = ((depth - depth_min) / (depth_max - depth_min) * 255).astype(np.uint8)\n",
        "            \n",
        "            # 元のサイズにリサイズ\n",
        "            depth_resized = cv2.resize(depth_normalized, original_size, interpolation=cv2.INTER_LINEAR)\n",
        "            \n",
        "            # カラーマップを適用 (viridis)\n",
        "            depth_colored = cv2.applyColorMap(depth_resized, cv2.COLORMAP_VIRIDIS)\n",
        "            depth_colored = cv2.cvtColor(depth_colored, cv2.COLOR_BGR2RGB)\n",
        "            \n",
        "            # PILイメージに変換\n",
        "            depth_image = Image.fromarray(depth_colored)\n",
        "            \n",
        "            return image, depth_image\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error in depth estimation: {e}\")\n",
        "            return None, None\n",
        "\n",
        "# グローバルAPI インスタンス\n",
        "print(\"Initializing DepthEstimation API...\")\n",
        "api = DepthEstimationAPI()\n",
        "\n",
        "def gradio_interface():\n",
        "    \"\"\"Gradio インターフェースの設定\"\"\"\n",
        "    \n",
        "    interface = gr.Interface(\n",
        "        fn=api.estimate_depth,\n",
        "        inputs=gr.Image(type=\"pil\", label=\"入力画像\"),\n",
        "        outputs=[\n",
        "            gr.Image(type=\"pil\", label=\"元画像\"),\n",
        "            gr.Image(type=\"pil\", label=\"深度マップ\")\n",
        "        ],\n",
        "        title=\"DepthAnything V2 深度推定API\",\n",
        "        description=\"DepthAnything V2モデルを使用した高精度深度推定\",\n",
        "        allow_flagging=\"never\"\n",
        "    )\n",
        "    \n",
        "    return interface\n",
        "\n",
        "# Gradio インターフェースを作成\n",
        "print(\"Setting up Gradio interface...\")\n",
        "demo = gradio_interface()\n",
        "\n",
        "# ngrokでパブリックURLを取得\n",
        "print(\"Setting up ngrok tunnel...\")\n",
        "public_url = ngrok.connect(7860)\n",
        "print(f\"\\n\" + \"=\" * 60)\n",
        "print(f\"🚀 API Server is running!\")\n",
        "print(f\"Public URL: {public_url}\")\n",
        "print(f\"\\n📋 Frontend環境変数に設定してください:\")\n",
        "print(f\"NEXT_PUBLIC_BACKEND_URL={public_url}\")\n",
        "print(f\"=\" * 60)\n",
        "\n",
        "# サーバー起動\n",
        "demo.launch(\n",
        "    server_name=\"0.0.0.0\",\n",
        "    server_port=7860,\n",
        "    share=False,\n",
        "    debug=True\n",
        ")\n",
        "'''\n",
        "\n",
        "# ファイルに保存\n",
        "with open('depth_api.py', 'w', encoding='utf-8') as f:\n",
        "    f.write(api_code)\n",
        "\n",
        "print(\"APIコード準備完了\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. APIサーバー起動\n",
        "\n",
        "このセルを実行するとAPIサーバーが起動し、パブリックURLが表示されます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# APIサーバーを起動\n",
        "exec(open('depth_api.py').read())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. フロントエンド設定\n",
        "\n",
        "上で表示されたURLを、フロントエンドの環境変数に設定してください。\n",
        "\n",
        "```bash\n",
        "# frontend/.env.local\n",
        "NEXT_PUBLIC_BACKEND_URL=https://xxxxxxxx.ngrok.io\n",
        "```\n",
        "\n",
        "## 使用上の注意\n",
        "\n",
        "1. **Colab セッション**: Colabは12時間でセッションが切れます\n",
        "2. **ngrok URL**: 無料版は8時間で期限切れになります\n",
        "3. **GPU使用量**: T4 GPUを効率的に使用します\n",
        "4. **メモリ使用量**: 約2-3GB程度使用します\n",
        "\n",
        "## トラブルシューティング\n",
        "\n",
        "- モデル読み込みエラー: GPUメモリ不足の可能性があります\n",
        "- ngrok接続エラー: トークンの設定を確認してください\n",
        "- タイムアウトエラー: ランタイムを再起動してください"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}