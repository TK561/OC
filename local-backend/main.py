"""
å±•ç¤ºç”¨ãƒ­ãƒ¼ã‚«ãƒ«æ·±åº¦æ¨å®šAPI
å®Œå…¨ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒ»é«˜ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç‰ˆ
"""

from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import torch
from transformers import AutoImageProcessor, AutoModelForDepthEstimation
from PIL import Image
import numpy as np
import cv2
import io
import base64
import gc
import logging
from datetime import datetime
import os

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('exhibition_api.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

app = FastAPI(
    title="å±•ç¤ºç”¨æ·±åº¦æ¨å®šAPI",
    description="å®Œå…¨ãƒ­ãƒ¼ã‚«ãƒ«ãƒ»é«˜ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ·±åº¦æ¨å®šã‚·ã‚¹ãƒ†ãƒ ",
    version="1.0.0"
)

# CORSè¨­å®š (ãƒ­ãƒ¼ã‚«ãƒ«å°‚ç”¨)
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000",
        "http://127.0.0.1:3000",
        "http://localhost:3001"  # é–‹ç™ºç”¨
    ],
    allow_credentials=True,
    allow_methods=["GET", "POST"],
    allow_headers=["*"],
)

class ExhibitionDepthEstimator:
    def __init__(self):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.model_name = "depth-anything/Depth-Anything-V2-Small-hf"
        
        logger.info(f"ğŸ›ï¸ å±•ç¤ºç”¨ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–é–‹å§‹")
        logger.info(f"ğŸ”§ ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {self.device}")
        
        try:
            # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
            self.processor = AutoImageProcessor.from_pretrained(self.model_name)
            self.model = AutoModelForDepthEstimation.from_pretrained(self.model_name)
            self.model.to(self.device)
            self.model.eval()  # æ¨è«–ãƒ¢ãƒ¼ãƒ‰
            
            # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®š
            self.max_image_size = 2048
            self.allowed_formats = ["image/jpeg", "image/png", "image/webp"]
            self.processing_count = 0
            
            logger.info(f"âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†: {self.model_name}")
            logger.info(f"ğŸ”’ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®šå®Œäº†")
            
        except Exception as e:
            logger.error(f"âŒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            raise e
    
    def validate_image(self, file: UploadFile):
        """ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®å®‰å…¨æ€§æ¤œè¨¼"""
        # ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ãƒã‚§ãƒƒã‚¯
        if file.content_type not in self.allowed_formats:
            raise HTTPException(
                status_code=400,
                detail=f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„å½¢å¼: {file.content_type}"
            )
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯ (10MBåˆ¶é™)
        if hasattr(file, 'size') and file.size > 10 * 1024 * 1024:
            raise HTTPException(
                status_code=400,
                detail="ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã™ãã¾ã™ (æœ€å¤§10MB)"
            )
        
        return True
    
    def process_image(self, image_data: bytes):
        """ã‚»ã‚­ãƒ¥ã‚¢ãªç”»åƒå‡¦ç†"""
        try:
            # ç”»åƒèª­ã¿è¾¼ã¿
            image = Image.open(io.BytesIO(image_data)).convert('RGB')
            original_size = image.size
            
            # ã‚µã‚¤ã‚ºåˆ¶é™
            if max(image.size) > self.max_image_size:
                image.thumbnail((self.max_image_size, self.max_image_size), Image.Resampling.LANCZOS)
                logger.info(f"ğŸ“ ç”»åƒãƒªã‚µã‚¤ã‚º: {original_size} â†’ {image.size}")
            
            return image, original_size
            
        except Exception as e:
            logger.error(f"âŒ ç”»åƒå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            raise HTTPException(status_code=400, detail="ç”»åƒã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
    
    def estimate_depth(self, image: Image.Image):
        """æ·±åº¦æ¨å®šå‡¦ç†"""
        try:
            # å‰å‡¦ç†
            inputs = self.processor(images=image, return_tensors="pt")
            inputs = {k: v.to(self.device) for k, v in inputs.items()}
            
            # æ¨è«–å®Ÿè¡Œ
            with torch.no_grad():
                outputs = self.model(**inputs)
                predicted_depth = outputs.predicted_depth
            
            # å¾Œå‡¦ç†
            depth = predicted_depth.squeeze().cpu().numpy()
            
            # æ­£è¦åŒ–
            depth_min = depth.min()
            depth_max = depth.max()
            depth_normalized = ((depth - depth_min) / (depth_max - depth_min) * 255).astype(np.uint8)
            
            # å…ƒã®ã‚µã‚¤ã‚ºã«ãƒªã‚µã‚¤ã‚º
            depth_resized = cv2.resize(
                depth_normalized, 
                (image.size[0], image.size[1]), 
                interpolation=cv2.INTER_LINEAR
            )
            
            # ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—é©ç”¨
            depth_colored = cv2.applyColorMap(depth_resized, cv2.COLORMAP_VIRIDIS)
            depth_colored = cv2.cvtColor(depth_colored, cv2.COLOR_BGR2RGB)
            
            # PILã‚¤ãƒ¡ãƒ¼ã‚¸ã«å¤‰æ›
            depth_image = Image.fromarray(depth_colored)
            
            # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            del inputs, outputs, predicted_depth, depth, depth_normalized, depth_resized, depth_colored
            
            return depth_image
            
        except Exception as e:
            logger.error(f"âŒ æ·±åº¦æ¨å®šã‚¨ãƒ©ãƒ¼: {e}")
            raise HTTPException(status_code=500, detail="æ·±åº¦æ¨å®šå‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ")
        
        finally:
            # GPU ãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            gc.collect()
    
    def encode_image_to_base64(self, image: Image.Image, format='PNG'):
        """ç”»åƒã‚’Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰"""
        buffer = io.BytesIO()
        image.save(buffer, format=format)
        encoded = base64.b64encode(buffer.getvalue()).decode()
        return f"data:image/{format.lower()};base64,{encoded}"

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
estimator = ExhibitionDepthEstimator()

@app.get("/")
async def root():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    return {
        "status": "ğŸ›ï¸ å±•ç¤ºç”¨æ·±åº¦æ¨å®šAPIç¨¼åƒä¸­",
        "device": estimator.device,
        "processed_count": estimator.processing_count,
        "timestamp": datetime.now().isoformat()
    }

@app.get("/health")
async def health_check():
    """è©³ç´°ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    gpu_memory = None
    if torch.cuda.is_available():
        gpu_memory = {
            "allocated": f"{torch.cuda.memory_allocated() / 1024**3:.2f}GB",
            "reserved": f"{torch.cuda.memory_reserved() / 1024**3:.2f}GB"
        }
    
    return {
        "status": "healthy",
        "device": estimator.device,
        "gpu_memory": gpu_memory,
        "processed_count": estimator.processing_count,
        "model": estimator.model_name
    }

@app.post("/api/depth-estimation")
async def estimate_depth_api(file: UploadFile = File(...)):
    """æ·±åº¦æ¨å®šAPI"""
    request_id = f"req_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{estimator.processing_count}"
    
    try:
        logger.info(f"ğŸ“¥ æ–°ã—ã„ãƒªã‚¯ã‚¨ã‚¹ãƒˆ: {request_id}")
        estimator.processing_count += 1
        
        # å…¥åŠ›æ¤œè¨¼
        estimator.validate_image(file)
        
        # ç”»åƒãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        image_data = await file.read()
        logger.info(f"ğŸ“Š ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {len(image_data)} bytes")
        
        # ç”»åƒå‡¦ç†
        image, original_size = estimator.process_image(image_data)
        
        # æ·±åº¦æ¨å®šå®Ÿè¡Œ
        depth_image = estimator.estimate_depth(image)
        
        # Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        original_base64 = estimator.encode_image_to_base64(image)
        depth_base64 = estimator.encode_image_to_base64(depth_image)
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ä½œæˆ
        response = {
            "success": True,
            "data": [original_base64, depth_base64],  # Gradioäº’æ›å½¢å¼
            "metadata": {
                "request_id": request_id,
                "model": "DepthAnything-V2-Local",
                "original_size": original_size,
                "processed_size": image.size,
                "device": estimator.device,
                "security": "å®Œå…¨ãƒ­ãƒ¼ã‚«ãƒ«å‡¦ç†",
                "timestamp": datetime.now().isoformat()
            }
        }
        
        logger.info(f"âœ… å‡¦ç†å®Œäº†: {request_id}")
        
        # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        del image_data, image, depth_image
        gc.collect()
        
        return JSONResponse(content=response)
        
    except HTTPException as he:
        logger.warning(f"âš ï¸ ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼ {request_id}: {he.detail}")
        raise he
        
    except Exception as e:
        logger.error(f"âŒ å‡¦ç†ã‚¨ãƒ©ãƒ¼ {request_id}: {e}")
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "error": "ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ",
                "request_id": request_id
            }
        )
    
    finally:
        # æœ€çµ‚ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        gc.collect()

@app.post("/api/clear-cache")
async def clear_cache():
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ï¼ˆå±•ç¤ºç”¨ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ï¼‰"""
    try:
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        gc.collect()
        
        logger.info("ğŸ§¹ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢å®Ÿè¡Œ")
        
        return {
            "success": True,
            "message": "ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢å®Œäº†",
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"âŒ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ã‚¨ãƒ©ãƒ¼: {e}")
        return JSONResponse(
            status_code=500,
            content={"success": False, "error": str(e)}
        )

if __name__ == "__main__":
    import uvicorn
    
    logger.info("ğŸ›ï¸ å±•ç¤ºç”¨æ·±åº¦æ¨å®šã‚·ã‚¹ãƒ†ãƒ èµ·å‹•")
    logger.info("ğŸ”’ å®Œå…¨ãƒ­ãƒ¼ã‚«ãƒ«ãƒ»é«˜ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ¢ãƒ¼ãƒ‰")
    
    uvicorn.run(
        app, 
        host="0.0.0.0", 
        port=8000,
        log_level="info",
        access_log=True
    )