# ğŸš€ ä»Šã™ãã‚„ã‚‹ã“ã¨ - å®Œå…¨æ‰‹é †ãƒªã‚¹ãƒˆ

## ğŸ“± **Step 1: Google Colab ã§APIèµ·å‹•** (5åˆ†)

1. **Google Colab ã‚’é–‹ã**
   ```
   https://colab.research.google.com/
   ```

2. **GPUè¨­å®š**
   - `ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ` â†’ `ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã®ã‚¿ã‚¤ãƒ—ã‚’å¤‰æ›´` â†’ `GPU` â†’ `ä¿å­˜`

3. **æ–°ã—ã„ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ä½œæˆã—ã¦ä»¥ä¸‹ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œ**
   ```python
   # ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
   !pip install torch torchvision transformers gradio pyngrok opencv-python-headless Pillow numpy
   
   # ngrokè¨­å®š
   import pyngrok
   from pyngrok import ngrok
   
   NGROK_TOKEN = "ak_30Sd307Vvyan2iewy7g5tIVl4mQ"
   ngrok.set_auth_token(NGROK_TOKEN)
   print("âœ… ngrokèªè¨¼å®Œäº†")
   
   # å±•ç¤ºç”¨æ·±åº¦æ¨å®šAPI
   import torch
   import gradio as gr
   from transformers import AutoImageProcessor, AutoModelForDepthEstimation
   import numpy as np
   from PIL import Image
   import cv2
   
   class ExhibitionAPI:
       def __init__(self):
           self.device = "cuda" if torch.cuda.is_available() else "cpu"
           print(f"ğŸ”§ ãƒ‡ãƒã‚¤ã‚¹: {self.device}")
           
           self.processor = AutoImageProcessor.from_pretrained("depth-anything/Depth-Anything-V2-Small-hf")
           self.model = AutoModelForDepthEstimation.from_pretrained("depth-anything/Depth-Anything-V2-Small-hf")
           self.model.to(self.device)
           print("âœ… ãƒ¢ãƒ‡ãƒ«æº–å‚™å®Œäº†")
       
       def process(self, image):
           if image is None:
               return None, None
           
           try:
               if image.mode != 'RGB':
                   image = image.convert('RGB')
               
               inputs = self.processor(images=image, return_tensors="pt")
               inputs = {k: v.to(self.device) for k, v in inputs.items()}
               
               with torch.no_grad():
                   outputs = self.model(**inputs)
                   depth = outputs.predicted_depth.squeeze().cpu().numpy()
               
               depth_normalized = ((depth - depth.min()) / (depth.max() - depth.min()) * 255).astype(np.uint8)
               depth_colored = cv2.applyColorMap(depth_normalized, cv2.COLORMAP_VIRIDIS)
               depth_colored = cv2.cvtColor(depth_colored, cv2.COLOR_BGR2RGB)
               depth_image = Image.fromarray(depth_colored)
               
               return image, depth_image
           except Exception as e:
               print(f"ã‚¨ãƒ©ãƒ¼: {e}")
               return None, None
   
   api = ExhibitionAPI()
   
   interface = gr.Interface(
       fn=api.process,
       inputs=gr.Image(type="pil", label="ğŸ“· ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"),
       outputs=[gr.Image(type="pil", label="ğŸ“¸ å…ƒç”»åƒ"), gr.Image(type="pil", label="ğŸ¨ æ·±åº¦ãƒãƒƒãƒ—")],
       title="ğŸ›ï¸ å±•ç¤ºç”¨æ·±åº¦æ¨å®šAPI",
       description="ğŸ”’ ã‚»ã‚­ãƒ¥ã‚¢å‡¦ç† | âœ… å¤–éƒ¨æ¼æ´©ãªã— | ğŸ’° å®Œå…¨ç„¡æ–™",
       allow_flagging="never"
   )
   
   public_url = ngrok.connect(7860)
   print(f"\nğŸ‰ å±•ç¤ºç”¨APIèµ·å‹•å®Œäº†!")
   print(f"ğŸ“¡ Public URL: {public_url}")
   print(f"ğŸ“‹ Vercelè¨­å®šç”¨: NEXT_PUBLIC_BACKEND_URL={public_url}")
   
   interface.launch(server_name="0.0.0.0", server_port=7860, share=False)
   ```

4. **URLã‚’ã‚³ãƒ”ãƒ¼**
   ```
   ä¾‹: https://abc123.ngrok-free.app
   ```

---

## ğŸ“± **Step 2: Vercelç’°å¢ƒå¤‰æ•°è¨­å®š** (3åˆ†)

1. **Vercel Dashboard ã‚’é–‹ã**
   ```
   https://vercel.com/dashboard
   ```

2. **ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆé¸æŠ** â†’ **Settings** â†’ **Environment Variables**

3. **æ–°ã—ã„ç’°å¢ƒå¤‰æ•°è¿½åŠ **
   - **Name**: `NEXT_PUBLIC_BACKEND_URL`
   - **Value**: Step 1ã§å–å¾—ã—ãŸURLï¼ˆä¾‹: https://abc123.ngrok-free.appï¼‰
   - **Environment**: `Production`
   - **Save**

4. **å†ãƒ‡ãƒ—ãƒ­ã‚¤**
   - **Deployments** â†’ **Redeploy**

---

## ğŸ“± **Step 3: å‹•ä½œç¢ºèª** (1åˆ†)

1. **Vercelã‚¢ãƒ—ãƒªã«ã‚¢ã‚¯ã‚»ã‚¹**
   ```
   https://your-app.vercel.app
   ```

2. **ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ**
   - ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
   - ã€Œæ·±åº¦æ¨å®šå®Ÿè¡Œã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
   - 2-5ç§’ã§æ·±åº¦ãƒãƒƒãƒ—ãŒè¡¨ç¤ºã•ã‚Œã‚‹

3. **æˆåŠŸç¢ºèª**
   - âœ… **æˆåŠŸ**: ç·‘è‰²ã§ã€ŒDepthAnything-V2-Smallã€è¡¨ç¤º
   - âŒ **å¤±æ•—**: ã‚ªãƒ¬ãƒ³ã‚¸è‰²ã§ã€Œmock-gradient (ãƒ‡ãƒ¢)ã€è¡¨ç¤º

---

## ğŸ¯ **ã“ã‚Œã§å®Œäº†ï¼å±•ç¤ºã‚·ã‚¹ãƒ†ãƒ ç¨¼åƒä¸­**

### ğŸ”’ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä¿è¨¼
- âœ… ç”»åƒã¯å‡¦ç†å¾Œå³åº§å‰Šé™¤
- âœ… å¤–éƒ¨ã¸ã®ä¿å­˜ãªã—  
- âœ… å®Œå…¨ãƒ­ãƒ¼ã‚«ãƒ«å‡¦ç†

### ğŸ’° ã‚³ã‚¹ãƒˆ
- âœ… å®Œå…¨ç„¡æ–™

### â° 2æ—¥é–“é‹ç”¨
- **8æ™‚é–“æ¯**: æ–°ã—ã„ngrok URLç”Ÿæˆ â†’ Vercelç’°å¢ƒå¤‰æ•°æ›´æ–°
- **12æ™‚é–“æ¯**: Google Colab ã‚»ãƒƒã‚·ãƒ§ãƒ³å†èµ·å‹•

---

## ğŸš¨ **8æ™‚é–“å¾Œã®URLæ›´æ–°æ‰‹é †**

1. **Google Colab ã§æ–°ã—ã„URLç”Ÿæˆ**
   ```python
   # æ—¢å­˜ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§å®Ÿè¡Œ
   public_url = ngrok.connect(7861)  # ãƒãƒ¼ãƒˆç•ªå·ã‚’å¤‰æ›´
   print(f"æ–°ã—ã„URL: {public_url}")
   ```

2. **Vercelç’°å¢ƒå¤‰æ•°æ›´æ–°**
   - ä¸Šè¨˜ Step 2 ã‚’ç¹°ã‚Šè¿”ã—

3. **å‹•ä½œç¢ºèª**
   - ä¸Šè¨˜ Step 3 ã‚’ç¹°ã‚Šè¿”ã—

---

## ğŸ“ **å•é¡Œç™ºç”Ÿæ™‚**

### Google Colabæ¥ç¶šã‚¨ãƒ©ãƒ¼
â†’ ã‚»ãƒƒã‚·ãƒ§ãƒ³å†èµ·å‹• â†’ ã‚³ãƒ¼ãƒ‰å†å®Ÿè¡Œ

### ngrok URLæœŸé™åˆ‡ã‚Œ  
â†’ æ–°ã—ã„URLç”Ÿæˆ â†’ Vercelæ›´æ–°

### Vercelãƒ‡ãƒ—ãƒ­ã‚¤ã‚¨ãƒ©ãƒ¼
â†’ ç’°å¢ƒå¤‰æ•°ã®å€¤ç¢ºèª â†’ æ‰‹å‹•å†ãƒ‡ãƒ—ãƒ­ã‚¤

---

# ğŸ¯ **ä»Šã™ãå®Ÿè¡Œ: Step 1 ã‹ã‚‰é–‹å§‹ï¼**