# Google Colab å®Œå…¨å®Ÿè¡Œã‚³ãƒ¼ãƒ‰ï¼ˆã‚³ãƒ”ãƒšç”¨ï¼‰
# 1. æ–°ã—ã„ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ä½œæˆ
# 2. ãƒ©ãƒ³ã‚¿ã‚¤ãƒ  â†’ ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã®ã‚¿ã‚¤ãƒ—ã‚’å¤‰æ›´ â†’ GPU â†’ ä¿å­˜
# 3. ä»¥ä¸‹ã‚’1ã¤ã®ã‚»ãƒ«ã«ã‚³ãƒ”ãƒšã—ã¦å®Ÿè¡Œ

!pip install torch torchvision transformers gradio pyngrok opencv-python-headless Pillow numpy -q

import pyngrok
from pyngrok import ngrok
import torch
import gradio as gr
from transformers import AutoImageProcessor, AutoModelForDepthEstimation
import numpy as np
from PIL import Image
import cv2

# ngrokèªè¨¼
NGROK_TOKEN = "ak_30Sd307Vvyan2iewy7g5tIVl4mQ"
ngrok.set_auth_token(NGROK_TOKEN)
print("âœ… ngrokèªè¨¼å®Œäº†")

# APIåˆæœŸåŒ–
class ExhibitionAPI:
    def __init__(self):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"ğŸ”§ ãƒ‡ãƒã‚¤ã‚¹: {self.device}")
        
        print("ğŸ“¥ ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
        self.processor = AutoImageProcessor.from_pretrained("depth-anything/Depth-Anything-V2-Small-hf")
        self.model = AutoModelForDepthEstimation.from_pretrained("depth-anything/Depth-Anything-V2-Small-hf")
        self.model.to(self.device)
        print("âœ… ãƒ¢ãƒ‡ãƒ«æº–å‚™å®Œäº†")
    
    def process(self, image):
        if image is None:
            return None, None
        
        try:
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            inputs = self.processor(images=image, return_tensors="pt")
            inputs = {k: v.to(self.device) for k, v in inputs.items()}
            
            with torch.no_grad():
                outputs = self.model(**inputs)
                depth = outputs.predicted_depth.squeeze().cpu().numpy()
            
            depth_normalized = ((depth - depth.min()) / (depth.max() - depth.min()) * 255).astype(np.uint8)
            depth_colored = cv2.applyColorMap(depth_normalized, cv2.COLORMAP_VIRIDIS)
            depth_colored = cv2.cvtColor(depth_colored, cv2.COLOR_BGR2RGB)
            depth_image = Image.fromarray(depth_colored)
            
            # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            del inputs, outputs, depth, depth_normalized, depth_colored
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            
            return image, depth_image
        except Exception as e:
            print(f"ã‚¨ãƒ©ãƒ¼: {e}")
            return None, None

print("ğŸš€ APIåˆæœŸåŒ–ä¸­...")
api = ExhibitionAPI()

# Gradioã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
interface = gr.Interface(
    fn=api.process,
    inputs=gr.Image(type="pil", label="ğŸ“· ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"),
    outputs=[gr.Image(type="pil", label="ğŸ“¸ å…ƒç”»åƒ"), gr.Image(type="pil", label="ğŸ¨ æ·±åº¦ãƒãƒƒãƒ—")],
    title="ğŸ›ï¸ å±•ç¤ºç”¨æ·±åº¦æ¨å®šAPI",
    description="ğŸ”’ å®Œå…¨ã‚»ã‚­ãƒ¥ã‚¢ | âœ… å¤–éƒ¨æ¼æ´©ãªã— | ğŸ’° å®Œå…¨ç„¡æ–™ | â±ï¸ 2-5ç§’å‡¦ç†",
    allow_flagging="never"
)

# ngrok URLç”Ÿæˆ
public_url = ngrok.connect(7860)
print("\n" + "="*70)
print("ğŸ‰ å±•ç¤ºç”¨æ·±åº¦æ¨å®šAPIèµ·å‹•å®Œäº†!")
print(f"ğŸ“¡ Public URL: {public_url}")
print("\nğŸ”§ Vercelè¨­å®šæ‰‹é †:")
print("1. https://vercel.com/dashboard ã‚’é–‹ã")
print("2. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ â†’ Settings â†’ Environment Variables")
print("3. NEXT_PUBLIC_BACKEND_URL ã«ä»¥ä¸‹ã‚’è¨­å®š:")
print(f"   {public_url}")
print("4. Save â†’ Redeployã‚’ã‚¯ãƒªãƒƒã‚¯")
print("="*70)

# APIèµ·å‹•
interface.launch(server_name="0.0.0.0", server_port=7860, share=False)